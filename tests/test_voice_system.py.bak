import pytest_asyncio
"""
W.I.T. Voice System Integration Tests

Comprehensive tests for voice processing pipeline.
"""

import pytest
import asyncio
import numpy as np
import wave
import io
import json
import websockets
from unittest.mock import Mock, patch
import sys
import os

# Add project paths
sys.path.append(os.path.join(os.path.dirname(__file__), '../software/ai/voice'))
sys.path.append(os.path.join(os.path.dirname(__file__), '../software/backend/api'))

from voice_processor import (
    VoiceProcessor, ProcessingConfig, VoiceCommand,
    VoiceState, WorkshopVoiceAssistant
)


class TestVoiceProcessor:
    """Test voice processor functionality"""
    
    @pytest.fixture
    async def voice_processor(self):
        """Create voice processor instance"""
        config = ProcessingConfig(
            model_size="tiny",  # Use tiny model for tests
            device="cpu",
            enable_npu=False
        )
        processor = VoiceProcessor(config)
        await processor.start()
        yield processor
        await processor.stop()
        
    @pytest.fixture
    def sample_audio(self):
        """Generate sample audio data"""
        sample_rate = 16000
        duration = 2.0
        frequency = 440  # A4 note
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        # Add some noise
        noise = np.random.normal(0, 0.05, audio.shape)
        audio = audio + noise
        
        # Convert to int16
        audio_int16 = (audio * 32767).astype(np.int16)
        
        return audio_int16, sample_rate
        
    @pytest.mark.asyncio
    async def test_processor_initialization(self, voice_processor):
        """Test processor initializes correctly"""
        assert voice_processor.state == VoiceState.LISTENING
        stats = voice_processor.get_statistics()
        assert stats["transcriptions"] == 0
        assert stats["errors"] == 0
        
    @pytest.mark.asyncio
    async def test_audio_chunk_processing(self, voice_processor, sample_audio):
        """Test processing audio chunks"""
        audio_data, sample_rate = sample_audio
        chunk_size = int(sample_rate * 0.1)  # 100ms chunks
        
        # Process chunks
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            result = await voice_processor.process_audio_chunk(
                chunk, 
                i / sample_rate
            )
            
        # Check buffer
        stats = voice_processor.get_statistics()
        assert stats["buffer_size"] > 0
        
    @pytest.mark.asyncio
    async def test_vad_detection(self, voice_processor):
        """Test voice activity detection"""
        sample_rate = 16000
        
        # Generate silence
        silence = np.zeros(int(sample_rate * 0.5), dtype=np.int16)
        
        # Generate speech-like signal
        t = np.linspace(0, 0.5, int(sample_rate * 0.5))
        speech = np.sin(2 * np.pi * 200 * t) * 0.3  # Lower frequency
        speech_int16 = (speech * 32767).astype(np.int16)
        
        # Test silence
        is_speech = voice_processor._is_speech(silence)
        assert not is_speech
        
        # Test speech
        is_speech = voice_processor._is_speech(speech_int16)
        # Note: Simple tone might not trigger VAD
        
    @pytest.mark.asyncio
    async def test_command_parsing(self, voice_processor):
        """Test intent parsing"""
        test_commands = [
            ("start the 3D printer", "control", ["start", "printer"]),
            ("print the bracket design", "print", ["print", "bracket"]),
            ("what's the temperature", "query", ["temperature"]),
            ("emergency stop", "safety", ["emergency", "stop"]),
            ("create a cube 50mm", "design", ["create", "cube", "50"])
        ]
        
        for text, expected_intent, expected_keywords in test_commands:
            intent, entities, confidence = await voice_processor._parse_intent(text)
            
            # Check intent detection
            assert intent != "unknown", f"Failed to detect intent for: {text}"
            
            # For simple parser, just check if any keyword matches
            text_lower = text.lower()
            keyword_found = any(kw in text_lower for kw in expected_keywords)
            assert keyword_found, f"Keywords not found in: {text}"
            
    @pytest.mark.asyncio
    async def test_recording_functionality(self, voice_processor, sample_audio):
        """Test audio recording"""
        audio_data, sample_rate = sample_audio
        
        # Simulate wake word detection
        voice_processor.state = VoiceState.WAKE_WORD_DETECTED
        
        # Start recording
        max_duration = 5000  # 5 seconds
        result = await voice_processor.voice_start_recording(
            voice_processor, 
            max_duration
        )
        
        # Process some audio
        chunk_size = int(sample_rate * 0.1)
        for i in range(0, min(len(audio_data), int(sample_rate * 2)), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            await voice_processor.process_audio_chunk(chunk, i / sample_rate)
            
        # Stop recording
        await voice_processor.voice_stop_recording(voice_processor)
        
        # Check state
        assert voice_processor.state == VoiceState.PROCESSING
        
    @pytest.mark.asyncio
    async def test_workshop_assistant(self, voice_processor):
        """Test workshop assistant integration"""
        assistant = WorkshopVoiceAssistant(voice_processor)
        
        # Track command executions
        executed_commands = []
        
        async def mock_handler(command):
            executed_commands.append(command)
            
        # Override handlers with mock
        for intent in ["print", "control", "safety"]:
            voice_processor.register_command_handler(intent, mock_handler)
            
        # Create test command
        command = VoiceCommand(
            text="start the 3D printer",
            intent="control",
            entities={"action": "start", "equipment": "printer"},
            confidence=0.85,
            timestamp=asyncio.get_event_loop().time(),
            audio_duration=2.5
        )
        
        # Execute
        await voice_processor._execute_command(command)
        
        # Verify execution
        assert len(executed_commands) > 0
        assert executed_commands[0].text == "start the 3D printer"


class TestVoiceAPI:
    """Test voice API endpoints"""
    
    @pytest.fixture
    def api_client(self):
        """Create test client"""
        from fastapi.testclient import TestClient
        from voice_api import router
        
        # Create test app
        from fastapi import FastAPI
        app = FastAPI()
        app.include_router(router)
        
        return TestClient(app)
        
    def test_status_endpoint(self, api_client):
        """Test /status endpoint"""
        response = api_client.get("/api/v1/voice/status")
        
        # Should fail without initialization
        assert response.status_code == 503
        
    def test_health_check(self, api_client):
        """Test /health endpoint"""
        response = api_client.get("/api/v1/voice/health")
        
        # Should fail without initialization
        assert response.status_code == 503
        
    def test_commands_list(self, api_client):
        """Test /commands endpoint"""
        response = api_client.get("/api/v1/voice/commands")
        assert response.status_code == 200
        
        commands = response.json()
        assert len(commands) > 0
        assert any(cmd["intent"] == "print" for cmd in commands)
        
    @pytest.mark.asyncio
    async def test_websocket_connection(self):
        """Test WebSocket streaming"""
        # This would require a running server
        # Placeholder for WebSocket test
        pass


class TestAudioDriver:
    """Test audio driver functionality"""
    
    def test_audio_format_conversion(self):
        """Test audio format conversion utilities"""
        # Generate test data
        samples = 1000
        int16_data = np.random.randint(-32768, 32767, samples, dtype=np.int16)
        
        # Convert to float32
        float32_data = int16_data.astype(np.float32) / 32768.0
        
        # Verify range
        assert np.all(float32_data >= -1.0)
        assert np.all(float32_data <= 1.0)
        
    def test_audio_interleaving(self):
        """Test audio channel interleaving"""
        channels = 4
        samples = 1000
        
        # Create separate channel data
        channel_data = []
        for ch in range(channels):
            data = np.sin(2 * np.pi * (440 + ch * 100) * 
                         np.arange(samples) / 16000)
            channel_data.append(data)
            
        # Interleave manually
        interleaved = np.zeros(samples * channels)
        for i in range(samples):
            for ch in range(channels):
                interleaved[i * channels + ch] = channel_data[ch][i]
                
        # Verify structure
        assert len(interleaved) == samples * channels
        
    def test_circular_buffer(self):
        """Test circular buffer implementation"""
        buffer_size = 1000
        buffer = np.zeros(buffer_size)
        write_idx = 0
        
        # Write data in chunks
        chunk_size = 100
        for i in range(20):  # Write 2x buffer size
            chunk = np.ones(chunk_size) * i
            
            # Circular write
            end_idx = write_idx + chunk_size
            if end_idx <= buffer_size:
                buffer[write_idx:end_idx] = chunk
            else:
                # Wrap around
                first_part = buffer_size - write_idx
                buffer[write_idx:] = chunk[:first_part]
                buffer[:chunk_size - first_part] = chunk[first_part:]
                
            write_idx = (write_idx + chunk_size) % buffer_size
            
        # Buffer should contain latest values
        assert buffer[write_idx - 1] == 19  # Last written value


class TestWakeWordDetection:
    """Test wake word detection system"""
    
    def test_mfcc_extraction(self):
        """Test MFCC feature extraction"""
        # Generate test signal
        sample_rate = 16000
        duration = 1.0
        frequency = 440
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        signal = np.sin(2 * np.pi * frequency * t)
        
        # Add formants (speech-like)
        signal += 0.5 * np.sin(2 * np.pi * 880 * t)
        signal += 0.3 * np.sin(2 * np.pi * 1320 * t)
        
        # Simple MFCC calculation would go here
        # For testing, just verify signal properties
        assert len(signal) == sample_rate * duration
        assert np.max(np.abs(signal)) <= 1.8  # Sum of amplitudes
        
    def test_wake_word_windowing(self):
        """Test wake word detection windowing"""
        window_ms = 1500
        stride_ms = 100
        sample_rate = 16000
        
        window_samples = int(window_ms * sample_rate / 1000)
        stride_samples = int(stride_ms * sample_rate / 1000)
        
        # Generate 3 seconds of audio
        audio_length = 3 * sample_rate
        
        # Calculate number of windows
        num_windows = (audio_length - window_samples) // stride_samples + 1
        
        assert num_windows > 0
        assert window_samples == 24000  # 1.5 seconds
        assert stride_samples == 1600   # 100ms


class TestSafetyFeatures:
    """Test safety-critical features"""
    
    @pytest.mark.asyncio
    async def test_emergency_stop(self, voice_processor):
        """Test emergency stop command handling"""
        assistant = WorkshopVoiceAssistant(voice_processor)
        
        emergency_triggered = False
        
        async def emergency_handler(command):
            nonlocal emergency_triggered
            if "emergency" in command.text.lower() or "stop" in command.text.lower():
                emergency_triggered = True
                
        voice_processor.register_command_handler("safety", emergency_handler)
        
        # Test emergency command
        command = VoiceCommand(
            text="EMERGENCY STOP",
            intent="safety",
            entities={"action": "emergency_stop"},
            confidence=1.0,
            timestamp=asyncio.get_event_loop().time(),
            audio_duration=1.0
        )
        
        await voice_processor._execute_command(command)
        assert emergency_triggered
        
    def test_command_validation(self):
        """Test dangerous command validation"""
        dangerous_commands = [
            "delete all files",
            "format the system",
            "override safety limits",
            "disable emergency stop"
        ]
        
        safe_commands = [
            "delete current print",
            "stop the printer",
            "pause operation",
            "check safety status"
        ]
        
        # In real implementation, would check command filtering
        for cmd in dangerous_commands:
            assert any(danger in cmd.lower() for danger in ["delete all", "format", "override safety", "disable emergency"])
            
        for cmd in safe_commands:
            # These should be allowed
            assert not all(danger in cmd.lower() for danger in ["delete all", "format", "override safety"])


# Performance benchmarks
class TestPerformance:
    """Performance benchmarks for voice system"""
    
    @pytest.mark.benchmark
    def test_audio_processing_latency(self, benchmark):
        """Benchmark audio processing latency"""
        sample_rate = 16000
        chunk_size = int(sample_rate * 0.02)  # 20ms
        chunk = np.random.randint(-32768, 32767, chunk_size, dtype=np.int16)
        
        def process_chunk():
            # Simulate processing
            energy = np.sqrt(np.mean(chunk.astype(np.float32) ** 2))
            return energy > 0.1
            
        result = benchmark(process_chunk)
        assert result is not None
        
    @pytest.mark.benchmark
    def test_mfcc_extraction_speed(self, benchmark):
        """Benchmark MFCC extraction speed"""
        sample_rate = 16000
        window_size = int(sample_rate * 0.025)  # 25ms window
        audio = np.random.randn(window_size)
        
        def extract_features():
            # Simulate MFCC extraction
            fft = np.fft.rfft(audio)
            power = np.abs(fft) ** 2
            return power[:40]  # Simulate mel filters
            
        result = benchmark(extract_features)
        assert len(result) == 40


if __name__ == "__main__":
    pytest.main([__file__, "-v"])